# 分布式锁

## 1、什么是分布式锁？

```
分布式锁原理同Java锁，为了保证只有一个线程操作同一份数据，只不过微服务线程可能不在同一的工程里面；
```

## 2、实现方式

##### 1、数据库分布式锁

```
维护一张数分布式锁的表：包含资源id，锁id，锁重入次数等信息；
```

##### 2、Redis分布式锁

```
加锁命令：SETNX key value，“SETNX”只有key不存在时设置value；
解锁命令：DEL key；
锁超时间：EXPIRE key timeout, 设置 key 的超时时间；
```

##### 3、Zookeeper分布式锁

```
1、多个客户端创建一个锁节点下的一个接一个的临时顺序节点;
2、如果自己是第一个临时顺序节点，那么这个客户端加锁成功；如果自己不是第一个节点，就对自己上一个节点加监听器
3、当某个客户端监听到上一个节点释放锁，自己就排到前面去了，此时继续执行步骤2，相当于是一个排队机制
```

# 分布式缓存

```
将重复使用的数据放到内存中，一次生成、多次使用，避免每次使用都去访问存储系统;
```

## 1、分布式缓存框架？

```
Redis、Memcache
```

## 2、缓存穿透

```
用户查询数据，在数据库没有，自然在缓存中也不会有；
```

##### 缓存穿透如何解决？

```
1、布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉；
2、缓存空结果，把空结果也缓存起来，下次同样的请求就可以直接返回空了；
```

## 3、缓存雪崩

```
由于原有缓存失效，新缓存未到期间，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力；
```

##### 解决缓存雪崩？

```
1、加锁 or 队列：保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上；
2、分散缓存失效时间：在原有的失效时间基础上增加一个1-5分钟的随机值，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件；
```

## 4、缓存预热

```
系统上线后，将相关的缓存数据直接加载到缓存系统，而不是等待用户访问才来触发缓存加载；
```

##### 如何实现？

```
1、数据量不大，可以在项目启动的时候自动进行加载；
2、数据量大，使用定时任务；
```

## 5、保证双写一致性？

```
* 缓存备用模式:
       - 读操作：先读缓存，缓存不存在则读数据库，然后将数据库结果写入缓存，同时返回响应；
       - 写操作：先删除缓存，然后再更新数据库（使用lazy计算思想：在数据需要被使用的时候做计算）
       高并发下可能会出现数据不一致问题；
* 内存队列：
       - 将缓存备用模式中的读操作和写操作串行化，可以串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况。
```

## 6、缓存热点？

```
大部分甚至所有的业务请求都命中同一份缓存数据，导致缓存服务器压力过大；
```

##### 解决方案？

```
缓存副本: 复制多份缓存副本，将请求分散到多个缓存服务器上，减轻缓存热点导致的单台缓存服务器压力；
```

# 降级/熔断/限流

## 1、降级

```
将系统中的某些业务或接口的功能降低，只提供部分功能或完全停掉所有功能
```

##### 实现

```
降级开关：要对系统进行降级，则在设计功能/模块时，就要考虑做一些开关，以便未来通过开关即可启停功能；
降级系统：还需要设计一个降级系统；
```

## 2、熔断

```
应对依赖的外部系统故障的情况；
```

## 3、限流

````
降低系统的请求压力；
````

### 实现

```
基于请求限流：限制访问请求数量；
   - 令牌算法：维护令牌队列，满了就丢弃任务，为空就阻塞;
   - 漏桶算法：设置固定的出桶速率，当进水(请求)速率大于出桶速率，就拒绝请求;
基于资源限流：限制系统内部影响性能的关键资源；
   - 逐步优化
排队限流：将用户请求放入一个队列中，等待一会儿；
```

# 负载均衡

```
解决高性能集群服务器任务分配的问题；
```

## 1、负载均衡算法？

```
* 普通轮询;
* 加权轮询;
* 负载最低优先;
* 性能最优优先;
* Hash类;
```

# 分布式锁

```
保障对所有节点操作的数据一致性，这些操作组成一个分布式事务，要么全部执行，要么全部不执行。
```

## 1、2PC

```
* 两阶段提交：投票阶段，提交阶段；
* 强一致性；
* 严重依赖数据库，不适合高并发的场景；
```

## 2、3PC

```
* 三阶段提交：询问阶段，准备阶段，提交阶段；
* 性能瓶颈，不适合高并发场景；
```

## 3、TCC   

```
* 补偿机制：Try（设置中间状态），Conform（提交事务），Cancel（回滚事务）；
* seata；
* 耦合性太高，业务代码臃肿且很难维护;
```

## 4、可靠消息最终一致性

```
* 消息队列：保证生产者对消息的100%可靠投递；
* Zookeeper： 保证消费者能够对未成功消费的消息进行重新消费；
* 适用于异步的服务调用积分系统或库存系统等类似系统；
```

